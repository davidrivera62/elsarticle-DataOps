@inproceedings{Grady2017,
abstract = {Big data analytic (BDA) systems leverage data distribution and parallel processing across a cluster of resources. This introduces a number of new challenges specifically for analytics. The analytics portion of the complete lifecycle has typically followed a waterfall process - completing one step before beginning the next. While efforts have been made to map different types of analytics to an agile methodology, the steps are often described as breaking activities into smaller tasks while the overall process is still consistent with step-by-step waterfall. BDA changes a number of the activities in the analytics lifecycle, as well as their ordering. The goal of agile analytics - to reach a point of optimality between generating value from data and the time spent getting there. This paper discusses the implications of an agile process for BDA in cleansing, transformation, and analytics.},
author = {Grady, Nancy W. and Payne, Jason A. and Parker, Huntley},
booktitle = {2017 IEEE International Conference on Big Data (Big Data)},
doi = {10.1109/BigData.2017.8258187},
file = {:C$\backslash$:/Users/david/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Grady, Payne, Parker - 2017 - Agile big data analytics AnalyticsOps for data science(2).pdf:pdf;:C$\backslash$:/Users/david/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Grady, Payne, Parker - 2017 - Agile big data analytics AnalyticsOps for data science(3).pdf:pdf},
isbn = {9781538627143},
keywords = {AnalyticsOps,Deep Learning,DevOps,Knowledge Discovery in Data Science,advanced analytics,agile development,analytics,analytics lifecycle,analyticsops,big data analytics,data,data science,data science process models,deep learning,devops,discovery in data science,knowledge,lifecycle,machine learning,science process models},
month = {dec},
pages = {2331--2339},
publisher = {IEEE},
title = {{Agile big data analytics: AnalyticsOps for data science}},
url = {http://ieeexplore.ieee.org/document/8258187/},
volume = {2018-Janua},
year = {2017}
}
@misc{ECKERSON2018,
author = {ECKERSON, WAYNE W.},
booktitle = {Eckerson Group},
title = {{DataOps Explained: A Remedy For Ailing Data Pipelines}},
url = {https://www.eckerson.com/articles/dataops-explained-a-remedy-for-ailing-data-pipelines},
urldate = {2018-06-15},
year = {2018}
}
@article{Chen2016,
abstract = {Big data as a Service (BDaaS) provides a viable alternative to$\backslash$ncircumvent many obstacles in implementing a big data strategy. Many$\backslash$nBDaaS vendors are providing cloud platforms utilizing microservices and$\backslash$nDevOps technologies to enable big data analytics for organizations that$\backslash$nseek cost-effective and elastic deployments. However, existing models of$\backslash$nBDaaS are mostly proprietary, closed-world operations and this can limit$\backslash$nthe potential for innovation. In this article, we argue for a new model$\backslash$ncalled the Neo-Metropolis model-a variant of the Metropolis model-that$\backslash$noffers an organized, coherent set of open-world innovation opportunities$\backslash$nfor vendors as well as for the platform's edge customers. We identify$\backslash$nNeo-Metropolis model characteristics and illustrate Neo-Metropolis$\backslash$nprinciples for developing BDaaS using a case study of Cisco's Intercloud$\backslash$nAnalytics platform. The implications of the Neo-Metropolis model are far$\backslash$nbeyond just BDaaS and it is foreseen to be an important model for future$\backslash$nservice platform development.},
author = {Chen, Hong-Mei and Kazman, Rick and Haziyev, Serge and Kropov, Valentyn and Chtchourov, Dmitri},
doi = {10.1109/HICSS.2016.674},
file = {:C$\backslash$:/Users/david/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen et al. - 2016 - Big Data as a Service A Neo-Metropolis Model Approach for Innovation(3).pdf:pdf;:C$\backslash$:/Users/david/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen et al. - 2016 - Big Data as a Service A Neo-Metropolis Model Approach for Innovation(4).pdf:pdf},
isbn = {978-0-7695-5670-3},
issn = {978-0-7695-5670-3},
journal = {2016 49th Hawaii International Conference on System Sciences (HICSS)},
pages = {5458--5467},
title = {{Big Data as a Service: A Neo-Metropolis Model Approach for Innovation}},
url = {http://ieeexplore.ieee.org/document/7427862/},
year = {2016}
}
@article{Sharma2017,
abstract = {The CRISP-DM methodology is commonly used in data
analytics exercises within an organisation to provide system and
structure to data mining processes. However, in providing a
rigorous framework, CRISP-DM overlooks two facets of data
analytics in organisational contexts; data mining exercises are far
more agile and subject to change than presumed in CRISP-DM
and central decisions regarding the interpretation of patterns
discovered and the direction of analytics exercises are typically
not made by individuals but by committees or groups within an
organisation. The current study provides a case study of data
mining in a hospital setting and suggests how the agile nature of
an analytics exercise and the group reasoning inherent in key
decisions can be accommodated within a CRISP-DM
methodology. },
author = {Sharma, Vishakha and Stranieri, Andrew and Ugon, Julien and Vamplew, Peter and Martin, Laura},
doi = {10.1145/3093241.3093273},
file = {:C$\backslash$:/Users/david/Dropbox/UNAL/2018-1/Tesis/DevOps - State of the Art/Refrences/CRISP-DM/sharma2017.pdf:pdf},
isbn = {9781450352413},
journal = {Proceedings of the International Conference on Compute and Data Analysis  - ICCDA '17},
keywords = {agile data mining,crisp,data analytics,decision support systems,health analytics,reasoning,systems applications},
pages = {109--113},
title = {{An Agile Group Aware Process beyond CRISP-DM}},
url = {http://dl.acm.org/citation.cfm?doid=3093241.3093273},
year = {2017}
}
@misc{Madsen2017,
author = {Madsen, Martin John},
keywords = {Agile Technique,DevOps,DevOps Technique,Predictive Analytics Solutions,agile,analytics},
mendeley-tags = {Agile Technique,DevOps,DevOps Technique,Predictive Analytics Solutions,agile,analytics},
title = {{Developing Predictive Analytics Solutions Using Agile/DevOps Techniques}},
url = {https://dminc.com/blog/developing-predictive-analytics-solutions-using-agiledevops-techniques/},
urldate = {2018-09-20},
year = {2017}
}
@inproceedings{Ereth2018a,
abstract = {Organizations seek to streamline their data and analytics structures in order to meet increasingly demanding business requirements. This can be difficult due to complex and fast-moving data landscapes. DataOps promises a remedy by combining an integrated and process-oriented perspective on data with automation and methods from agile software engineering, like DevOps, to improve quality, speed, and collaboration and promote a culture of continuous improvement. The goal of this ongoing research is to elaborate DataOps as a new discipline. For this, it explores the body of knowledge and presents a working definition of DataOps as well as an initial research framework based on an ex-plorative literature review and eight interviews with industry experts.},
author = {Ereth, Julian},
booktitle = {CEUR Workshop Proceedings},
file = {:C$\backslash$:/Users/david/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ereth - Unknown - DataOps-Towards a Definition.pdf:pdf},
keywords = {Agile,Analytics,DataOps,DevOps},
title = {{DataOps-Towards a Definition}},
year = {2018}
}
@article{Chen2016b,
abstract = {This article contributes an architecture-centric methodology, called AABA (Architecture-centric Agile Big data Analytics), to address the technical, organizational, and rapid technology change challenges of both big data system development and agile delivery of big data analytics for Web-based Systems (WBS). As the first of its kind, AABA fills a methodological void by adopting an architecture-centric approach, advancing and integrating software architecture analysis and design, big data modeling and agile practices. This article describes how AABA was developed, evolved and validated simultaneously in 10 empirical WBS case studies through 3 CPR (Collaborative Practice Research) cycles. In addition, this article presents an 11th case study illustrating the processes, methods and techniques/tools in AABA for cost-effectively achieving business goals and architecture agility in a large scale WBS. All 11 case studies showed that architecture-centric design, development, and operation is key to taming technical complexity and achieving agility necessary for successful WBS big data analytics development. Our contribution is novel and important. The use of reference architectures, a design concepts catalog and architectural spikes in AABA are advancements to architecture design methods. In addition, our architecture-centric approach to DevOps was critical for achieving strategic control over continuous big data value delivery for WBS.},
author = {Chen, Hong-Mei and Kazman, Rick and Haziyev, Serge},
doi = {10.1109/TBDATA.2016.2564982},
file = {:C$\backslash$:/Users/david/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen, Kazman, Haziyev - 2016 - Agile Big Data Analytics for Web-Based Systems An Architecture-Centric Approach.pdf:pdf},
isbn = {9780769556703},
issn = {2332-7790},
journal = {IEEE Transactions on Big Data},
number = {3},
pages = {234--248},
title = {{Agile Big Data Analytics for Web-Based Systems: An Architecture-Centric Approach}},
url = {http://ieeexplore.ieee.org/document/7468484/},
volume = {2},
year = {2016}
}
@article{Chen2015a,
abstract = {Big data as a Service (BDaaS) provides a viable strategy for organizations to implement scalable, tailorable big data infrastructure and applications built on this infrastructure. New trends in the BDaaS market are moving toward an open world model -- what we call the Neo-Metropolis model -- for developing BDaaS platforms. The key to the success of such large-scale technology-agnostic platforms, we posit, is an architectural strategy revolving around microservices and DevOps. This article presents the results of an action research with a Neo-Metropolis BDaaS vendor and illustrates how architectural support for DevOps is critical in achieving desired system qualities and enabling platform success. This research contributes to illuminate best practices of DevOps, and to validate and augment a set of DevOps tactics previously developed, while adding and recategorizing new instances of well-established architectural tactics.},
author = {Chen, Hong Mei and Kazman, Rick and Haziyev, Serge and Kropov, Valentyn and Chtchourov, Dmitri},
doi = {10.1109/SRDSW.2015.14},
file = {:C$\backslash$:/Users/david/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen et al. - 2015 - Architectural Support for DevOps in a Neo-Metropolis BDaaS Platform.pdf:pdf},
isbn = {978-1-5090-0092-0},
issn = {10609857},
journal = {Proceedings of the IEEE Symposium on Reliable Distributed Systems},
keywords = {big data,software architecture,tactics},
pages = {25--30},
title = {{Architectural Support for DevOps in a Neo-Metropolis BDaaS Platform}},
volume = {2016-Janua},
year = {2015}
}
@book{Casale2018,
abstract = {One of the most stressing challenges in our culture is the demographic change. On the one hand, people become older and older, at the same time less young people are available in order to support the elderly. Currently, this fact already provides a number of social impacts that need to be solved in the near future. This paper concentrates on the integration of mobile devices in scenarios that allow elderly people to age successfully. Here, the term "aging successfully" refers to broad range of aspects from health to social life of elderly people. A special focus of this paper lies in the question whether services deployed to a mobile device provide advantages in the area of aging successfully. In order to answer this question, both technical challenges are explained and solved by example architectures, and scenarios that benefit from services deployed to mobile devices are explained. {\textcopyright} Springer-Verlag Berlin Heidelberg 2013.},
archivePrefix = {arXiv},
arxivId = {arXiv:1507.08217v1},
author = {Casale, Giuliano and B, Chen Li},
doi = {10.1007/978-3-319-79090-9},
eprint = {arXiv:1507.08217v1},
file = {:C$\backslash$:/Users/david/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Casale, B - 2018 - Advances in Service-Oriented and Cloud Computing.pdf:pdf},
isbn = {978-3-319-79089-3},
issn = {18650929},
keywords = {Quality,Big data,UML,Eclipse,DevOps,big data,devops,eclipse,quality,uml},
number = {644869},
pages = {164--168},
publisher = {Springer International Publishing},
title = {{Advances in Service-Oriented and Cloud Computing}},
url = {http://link.springer.com/10.1007/978-3-319-79090-9},
volume = {824},
year = {2018}
}
@misc{Lazaro2018,
author = {Lazaro, Daniel},
title = {{DataOps + Un modelo estad{\'{i}}stico del comportamiento}},
url = {https://www.youtube.com/watch?v=ktf9XUh4CLI{\&}amp={\&}t=5467s},
year = {2018}
}
@techreport{Euston2017,
author = {Euston and Jarah},
file = {:C$\backslash$:/Users/david/Downloads/NEXLA{\_}DATAOPS{\_}REPORT{\_}2017.pdf:pdf},
institution = {Nexla},
title = {{The Def initive Data Operations Report}},
year = {2017}
}
@book{Thusoo2017,
abstract = {This book is an attempt to capture what we have learned building teams, systems, and processes in our constant pursuit of a data- driven approach for the companies that we have worked for, as well as companies that are clients of Qubole today. To capture the essence of those learnings has taken effort and support from a number of people.},
author = {Thusoo, Ashish and Sarma, Joydeep Sen},
file = {:C$\backslash$:/Users/david/Downloads/creating-a-data-driven-enterprise-with-dataops.pdf:pdf},
isbn = {9781491977835},
title = {{Creating a Data-Driven Enterprise with DataOps}},
url = {https://www.oreilly.com/data/free/creating-a-data-driven-enterprise-with-dataops.csp{\%}0A},
year = {2017}
}
@techreport{Kitchen2017,
author = {Kitchen, Data},
file = {:C$\backslash$:/Users/david/Downloads/DataOpsWhitePaper.pdf:pdf},
pages = {1--6},
title = {{High-Velocity Data Analytics with DataOps}},
year = {2017}
}
@techreport{Kitchen2017a,
abstract = {Data analytics teams challenged by inflexibility and poor quality have found that DataOps can address these and many other obstacles. DataOps includes tools and process improvements that enable faster, more responsive data analytics while maintaining a high level of quality and reliability. Data analytic teams can implement DataOps in seven simple steps: (1) Add data and logic tests, (2) Use a version control system, (3) Branch and merge, (4) Use multiple environments, (5) Reuse and containerize, (6) Parameterize your processing and (7) Use simple storage.},
author = {Kitchen, Data},
file = {:C$\backslash$:/Users/david/Downloads/DataKitchen{\_}7{\_}Steps{\_}White{\_}Paper.pdf:pdf},
pages = {1--6},
title = {{The Seven Steps to Implement DataOps}},
year = {2017}
}
@article{Dyba2008,
abstract = {Agile software development represents a major departure from traditional, plan-based approaches to software engineering. A systematic review of empirical studies of agile software development up to and including 2005 was conducted. The search strategy identified 1996 studies, of which 36 were identified as empirical studies. The studies were grouped into four themes: introduction and adoption, human and social factors, perceptions on agile methods, and comparative studies. The review investigates what is currently known about the benefits and limitations of, and the strength of evidence for, agile methods. Implications for research and practice are presented. The main implication for research is a need for more and better empirical studies of agile software development within a common research agenda. For the industrial readership, the review provides a map of findings, according to topic, that can be compared for relevance to their own settings and situations. {\textcopyright} 2008 Elsevier B.V. All rights reserved.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Dyb{\aa}, Tore and Dings{\o}yr, Torgeir},
doi = {10.1016/j.infsof.2008.01.006},
eprint = {arXiv:1011.1669v3},
file = {:C$\backslash$:/Users/david/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Dyb{\aa}, Dings{\o}yr - 2008 - Empirical studies of agile software development A systematic review.pdf:pdf},
isbn = {9783642125744},
issn = {09505849},
journal = {Information and Software Technology},
keywords = {Agile software development,Empirical software engineering,Evidence-based software engineering,Extreme programming,Research synthesis,Scrum,Systematic review,XP},
number = {9-10},
pages = {833--859},
pmid = {22207224},
title = {{Empirical studies of agile software development: A systematic review}},
volume = {50},
year = {2008}
}
@inproceedings{Budgen2006,
abstract = {The objective of this report is to propose comprehensive guidelines for systematic literature reviews appropriate for software engineering researchers, including PhD students. A systematic literature review is a means of evaluating and interpreting all available research relevant to a particular research question, topic area, or phenomenon of interest. Systematic reviews aim to present a fair evaluation of a research topic by using a trustworthy, rigorous, and auditable methodology. The guidelines presented in this report were derived from three existing guidelines used by medical researchers, two books produced by researchers with social science backgrounds and discussions with researchers from other disciplines who are involved in evidence-based practice. The guidelines have been adapted to reflect the specific problems of software engineering research. The guidelines cover three phases of a systematic literature review: planning the review, conducting the review and reporting the review. They provide a relatively high level description. They do not consider the impact of the research questions on the review procedures, nor do they specify in detail the mechanisms needed to perform meta-analysis.},
address = {New York, New York, USA},
archivePrefix = {arXiv},
arxivId = {1304.1186},
author = {Budgen, David and Brereton, Pearl},
booktitle = {Proceeding of the 28th international conference on Software engineering - ICSE '06},
doi = {10.1145/1134285.1134500},
eprint = {1304.1186},
file = {:C$\backslash$:/Users/david/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Budgen, Brereton - 2006 - Performing systematic literature reviews in software engineering.pdf:pdf},
isbn = {1595933751},
issn = {00010782},
number = {4ve},
pages = {1051},
pmid = {10853839},
publisher = {ACM Press},
title = {{Performing systematic literature reviews in software engineering}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Guidelines+for+performing+Systematic+Literature+Reviews+in+Software+Engineering{\#}0{\%}5Cnhttp://www.dur.ac.uk/ebse/resources/Systematic-reviews-5-8.pdf http://portal.acm.org/citation.cfm?doid=11342},
volume = {45},
year = {2006}
}
@misc{Ereth2018,
author = {Ereth, Julian},
booktitle = {Eckerson Group},
title = {{Data Observability - A Crucial Property in a DataOps World}},
url = {https://www.eckerson.com/articles/data-observability-a-crucial-property-in-a-dataops-world},
year = {2018}
}
@article{Ereth2018b,
author = {Ereth, Julian and Eckerson, Wayne},
file = {:C$\backslash$:/Users/david/Downloads/DataOp{\_}Final.pdf:pdf},
number = {June},
title = {{DataOps : Industrializing Data and Analytics Strategies for Streamlining the Delivery of Insights}},
url = {https://www.eckerson.com/register?content=dataops-industrializing-data-and-analytics{\%}0A},
year = {2018}
}
@techreport{Whitmore2017a,
author = {Whitmore, Toph},
file = {:C$\backslash$:/Users/david/Downloads/DataOps{\_}Enterprise-Roles-Analyst-Insight.pdf:pdf},
institution = {Blue Hill Research},
number = {June},
pages = {1--9},
title = {{The New Way of Work : How DataOps Transforms Enterprise Roles What You Need to Know}},
year = {2017}
}
@misc{Mccan2018,
abstract = {In this blog I want to explore how DevOps is being applied in the industry today before we really dig in to applying DevOps to Machine Learning in the next blog. If this is the first blog you're reading, then you might want to start at the beginning. http://www.hyperbi.co.uk/applying-devops-to-data-science/},
author = {Mccan, Terry},
title = {{DevOps, DataOps and Machine Learning - Terry McCann}},
url = {http://www.hyperbi.co.uk/devops-dataops-and-machine-learning/},
urldate = {2018-08-05},
year = {2018}
}
@misc{Watson2017,
author = {Watson, Matt},
keywords = {DevOps,Metrics},
mendeley-tags = {DevOps,Metrics},
title = {{15 Metrics for DevOps Success}},
url = {https://stackify.com/15-metrics-for-devops-success/},
urldate = {2018-08-04},
year = {2017}
}
@misc{McCann2018,
author = {McCann, Terry},
title = {{An Introduction to DevOps}},
year = {2018}
}
@techreport{Arachchi2018,
abstract = {Agile practices with Continuous Integration and Continuous Delivery (CICD) pipeline approach has increased the efficiency of projects. In agile, new features are introduced to the system in each sprint delivery, and although it may be well developed, the delivery failures are possible due to performance issues. By considering delivery timeline, moving for system scaling is common solution in such situations. But, how much system should be scaled? System scale requires current system benchmark status and expected system status. Benchmarking the production is a critical task, as it interrupts the live system. The new version should go through a load test to measure expected system status. The traditional load test methods are unable to identify production performance behavior due to simulated traffic patterns are highly deviated from production. To overcome those issues, this approach has extended CICD pipeline to have three automation phases named benchmark, load test and scaling. It minimizes the system interruption by using test bench approach when system benchmarking and it uses the production traffic for load testing which gives more accurate results. Once benchmark and load test phases are completed, system scaling can be evaluated. Initially, the pipeline was developed using Jenkins CI server, Git repository and Nexus repository with Ansible automation. Then GoReplay is used for traffic duplication from production to test bench environment. Nagios monitoring is used to analyze the system behavior in each phase and the result of test bench has proven that scaling is capable to handle the same load while changing the application software, but it doesn't optimize response time of application at significant level and it helps to reduce the risk of application deployment by integrating this three phase approach as CICD automation extended feature. Thereby the research provides effective way to manage Agile based CICD projects.},
author = {Arachchi, S A I B S and Perera, Indika},
file = {:C$\backslash$:/Users/david/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Arachchi, Perera - 2018 - Continuous Integration and Continuous Delivery Pipeline Automation for Agile Software Project Management Gener.pdf:pdf},
keywords = {agile project management,configuration management,continuous delivery,continuous integration,version management},
title = {{Continuous Integration and Continuous Delivery Pipeline Automation for Agile Software Project Management Generative Detector View project Air Pollution Monitoring Through Crowdsourcing View project Indika Perera Continuous Integration and Continuous Delivery Pipeline Automation for Agile Software Project Management}},
url = {https://www.researchgate.net/publication/326406017},
year = {2018}
}
@article{Dharmapal2016,
abstract = {This journal introduces the reader the background of Big Data Analytics
and how efficiently Agile methodology can be applied to achieve the
business goal. The journal focus on giving background of Big Data and
how using Agile practices such as iterative, incremental, and
evolutionary style of development can be applied for Big Data Analytics.
This methodology brings in the advantage of involving business community
during development and continuous delivery of working user features.},
author = {Dharmapal, Surend Raj and Sikamani, K. Thirunadana},
doi = {10.1109/ICEEOT.2016.7754854},
file = {:C$\backslash$:/Users/david/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Dharmapal, Sikamani - 2016 - Big data analytics using agile model.pdf:pdf},
isbn = {978-1-4673-9939-5},
journal = {2016 International Conference on Electrical, Electronics, and Optimization Techniques (ICEEOT)},
keywords = {agile,analytics,big data,data,data analyst,development methodology,engineering,generated today is unstructured,or in a semi-structured,predictive tool,project management,software},
pages = {1088--1091},
title = {{Big data analytics using agile model}},
url = {http://ieeexplore.ieee.org/document/7754854/},
year = {2016}
}
@article{Larson2016,
abstract = {Agile methodologies were introduced in 2001. Since this time, practitioners have applied Agile methodologies to many delivery disciplines. This article explores the application of Agile methodologies and principles to business intelligence delivery and how Agile has changed with the evolution of business intelligence. Business intelligence has evolved because the amount of data generated through the internet and smart devices has grown exponentially altering how organizations and individuals use information. The practice of business intelligence delivery with an Agile methodology has matured; however, business intelligence has evolved altering the use of Agile principles and practices. The Big Data phenomenon, the volume, variety, and velocity of data, has impacted business intelligence and the use of information. New trends such as fast analytics and data science have emerged as part of business intelligence. This paper addresses how Agile principles and practices have evolved with business intelligence, as well as its challenges and future directions.},
author = {Larson, Deanne and Chang, Victor},
doi = {10.1016/j.ijinfomgt.2016.04.013},
file = {:C$\backslash$:/Users/david/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Larson, Chang - 2016 - A review and future direction of agile, business intelligence, analytics and data science(2).pdf:pdf},
isbn = {02684012},
issn = {02684012},
journal = {International Journal of Information Management},
keywords = {Agile methodologies,Analytics and big data,Business intelligence (BI),Lifecycle for BI and Big Data},
number = {5},
pages = {700--710},
publisher = {Elsevier Ltd},
title = {{A review and future direction of agile, business intelligence, analytics and data science}},
url = {http://dx.doi.org/10.1016/j.ijinfomgt.2016.04.013},
volume = {36},
year = {2016}
}
@article{Guerriero2017,
abstract = {With the onset of Big Data and Data-Intensive Applications (DIAs) exploiting such big data, the problem of offering pri-vacy guarantees to data owners becomes crucial, even more so with the emergence of DevOps development strategies where speed is paramount. This paper outlines this com-plex scenario and the challenges therein. On one hand, we outline a tool prototype that addresses the key challenge we found in industry, more specifically, assisting the process of continuous DIA architecting for the purpose of offering privacy-by-design guarantees. On the other hand we define a research roadmap in pursuit of a more correct and com-plete solution for ensured privacy-by-design in the context of Big Data DevOps.},
author = {Guerriero, Michele and Tamburri, Damian A. and Ridene, Youssef and Marconi, Francesco and Bersani, Marcello M. and Artac, Matej},
doi = {10.1145/3053600.3053631},
file = {:C$\backslash$:/Users/david/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Guerriero et al. - 2017 - Towards DevOps for Privacy-by-Design in Data-Intensive Applications.pdf:pdf},
isbn = {9781450348997},
journal = {Proceedings of the 8th ACM/SPEC on International Conference on Performance Engineering Companion  - ICPE '17 Companion},
keywords = {big data,devops,privacy-by-design,trace-checking},
pages = {139--144},
title = {{Towards DevOps for Privacy-by-Design in Data-Intensive Applications}},
url = {http://dl.acm.org/citation.cfm?doid=3053600.3053631},
year = {2017}
}
@article{Schmidt2018,
author = {Schmidt, Cecil and Sun, Wenying Nan},
doi = {10.1080/08874417.2016.1218308},
file = {:C$\backslash$:/Users/david/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Schmidt, Sun - 2018 - Synthesizing Agile and Knowledge Discovery Case Study Results.pdf:pdf},
issn = {23802057},
journal = {Journal of Computer Information Systems},
keywords = {Knowledge discovery,agile,case study,data mining,process model},
number = {2},
pages = {142--150},
publisher = {Taylor {\&} Francis},
title = {{Synthesizing Agile and Knowledge Discovery: Case Study Results}},
url = {http://dx.doi.org/10.1080/08874417.2016.1218308},
volume = {58},
year = {2018}
}
@article{Saltz2015,
abstract = {— As data continues to be produced in massive amounts, with increasing volume, velocity and variety, big data projects are growing in frequency and importance. However, the growth in the use of big data has outstripped the knowledge of how to support teams that need to do big data projects. In fact, while much has been written in terms of the use of algorithms that can help generate insightful analysis, much less has been written about methodologies, tools and frameworks that could enable teams to more effectively and efficiently " do " big data projects. Hence, this paper discusses the key research questions relating methodologies, tools and frameworks to improve big data team effectiveness as well as the potential goals for a big data process methodology. Finally, the paper also discusses related domains, such as software development, operations research and business intelligence, since these fields might provide insight into how to define a big data process methodology.},
author = {Saltz, Jeffrey S.},
doi = {10.1109/BigData.2015.7363988},
file = {:C$\backslash$:/Users/david/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Saltz - 2015 - The need for new processes, methodologies and tools to support big data teams and improve big data project effectiveness.pdf:pdf},
isbn = {9781479999255},
journal = {Proceedings - 2015 IEEE International Conference on Big Data, IEEE Big Data 2015},
keywords = {Big Data,Data Science,Process Methodology},
pages = {2066--2071},
title = {{The need for new processes, methodologies and tools to support big data teams and improve big data project effectiveness}},
year = {2015}
}
@book{Rose2016,
abstract = {think of this book as having three overarching concepts: • The first is that you should mine your own company for talent. You can't change your organization by hiring data science heroes. The best way to get value from data science is by changing part of your organization's focus from managing objectives to researching and exploring. • The second is that you should form small agile-like data teams that focus on delivering insights early and often. • Finally, you can only make real changes to your organization by telling compelling data stories. These stories are the best way to communicate your insights about your customers, challenges, and industry. Much of the “science” in data science comes from the scientific method. You're applying a scientific method to your data. This is an empirical approach to gaining new knowledge and insights. An empirical approach is where you gain new knowledge from observation and experimentation. When you dip your toe in the pool, you are using an empirical approach. You're running a xvi Introduction small experiment and then reacting to the results. If the water's too cold, you work on your tan. If the water's warm, you can jump right in. You don't have to be a statistician to be able to ask interesting questions or to run a small experiment. Many people in different fields can contribute to this method of inquiry. In fact, you often get the best questions and feedback when you have people from diverse backgrounds. This book divides the three big concepts into five parts. Each part is a skillset that you'll need for a data science mindset. • Part I goes into the language and technology behind data science. • Part II is about building your data science team. • Part III is about how your team will work together to deliver insights and knowledge. • Part IV is about how a data science team should think about data. • Part V helps you tell an interesting story. Most scientists will tell you that your results won't mean much if you can't communicate your story.},
author = {Rose, Doug},
booktitle = {2006 1st International Conference on Digital Information Management},
doi = {10.1007/978-1-4842-2253-9},
file = {:C$\backslash$:/Users/david/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Rose - 2016 - Data Science Create Teams Th at Ask the Right Questions and Deliver Real Value.pdf:pdf},
isbn = {978-1-4842-2253-9},
pages = {381--388},
title = {{Data Science: Create Teams Th at Ask the Right Questions and Deliver Real Value}},
url = {http://link.springer.com/10.1007/978-1-4842-2253-9},
year = {2016}
}
@techreport{Aslett2018,
abstract = {Mix a generous helping of agile development DevOps and statistical process control with analytics and data management, and you have DataKitchen's recipe for the automation and orchestration of analytics data pipelines to enable organizations to achieve their goal of becoming more data-driven. The company has created its DataOps platform for the automation and orchestration of analytics pipelines. The 451 Take We think DataKitchen has a compelling take on the requirements for becoming data-driven, especially as it is set up to address the cultural and process changes that come with transformational projects, and not just the tooling products or services. It is clearly early stages by the company's own admission, but we are seeing growing interest in the trends that are driving DataOps, if not necessarily the term itself, so we would expect engagement to increase. Even if that takes a few years to reach a tipping point in terms of significant mainstream adoption, DataKitchen can afford to be patient given that it is profitable and growing without outside investment.},
author = {Aslett, Matt},
file = {:C$\backslash$:/Users/david/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2018 - DataKitchen whets the appetite for mainstream consumption of DataOps.pdf:pdf},
institution = {451 Research Group},
title = {{DataKitchen whets the appetite for mainstream consumption of DataOps}},
url = {https://451research.com/report-short?entityId=95008},
year = {2018}
}
@misc{SadatNazrul2018,
author = {{Sadat Nazrul}, Syed},
title = {{DevOps for Data Scientists: Taming the Unicorn}},
url = {https://towardsdatascience.com/devops-for-data-scientists-taming-the-unicorn-6410843990de},
year = {2018}
}
@article{Valentine,
author = {Valentine, Crystal},
file = {:C$\backslash$:/Users/david/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Valentine - Unknown - DataOps an Agile Methodology for Data-Driven Organizations(3).pdf:pdf},
title = {{DataOps: an Agile Methodology for Data-Driven Organizations}},
url = {https://www.datascience.com}
}
@techreport{Whitmore2017,
author = {Whitmore, Toph},
file = {:C$\backslash$:/Users/david/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Whitmore - 2017 - DataOps The Collaborative Framework for Enterprise Data-Flow Orchestration(3).pdf:pdf},
number = {January},
pages = {1--14},
title = {{DataOps: The Collaborative Framework for Enterprise Data-Flow Orchestration}},
url = {https://www.datakitchen.io/content/RT-A0287-DataOpsDefined-TW-DataKitchen-Final.pdf},
year = {2017}
}
@book{Cook2017,
address = {Berkeley, CA},
author = {Cook, Joshua},
doi = {10.1007/978-1-4842-3012-1},
file = {:C$\backslash$:/Users/david/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Cook - 2017 - Docker for Data Science(3).pdf:pdf},
isbn = {978-1-4842-3011-4},
publisher = {Apress},
title = {{Docker for Data Science}},
url = {http://link.springer.com/10.1007/978-1-4842-3012-1},
year = {2017}
}
@article{Bergh2017,
abstract = {Many companies, including Amazon and Google, have turned instant fulfillment into competitive advantage and are being rewarded in the marketplace. As consumers adapt to this "new normal," the expectation of instant delivery is crossing into other domains. For example, data analytics users can't or won't wait weeks or months for new analytics. Data analytics teams that can successfully meet requirements for rapid delivery of new analytics will play a high-visibility role in helping their organizations compete in the on-demand economy. Enterprises can improve the speed and strength of analytics using a process and tools approach called DataOps, which draws from process innovations in software development and lean manufacturing. Organizations that correctly implement DataOps experience significant improvements in the ability to produce robust and adaptive analytics. DataOps may be implemented in seven simple steps without discarding an organization's existing analytics tools. [ABSTRACT FROM AUTHOR]},
author = {Bergh, Christopher and Benghiat, Gil},
file = {:C$\backslash$:/Users/david/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bergh, Benghiat - 2017 - Analytics at Amazon Speed The New Normal(3).pdf:pdf},
journal = {Business Intelligence Journal},
number = {2},
pages = {46--55},
title = {{Analytics at Amazon Speed: The New Normal}},
url = {https://tdwi.org/research/2017/05/business-intelligence-journal-vol-22-no-2.aspx},
volume = {22},
year = {2017}
}
@article{Smith2014,
author = {Smith, Micah J},
file = {:C$\backslash$:/Users/david/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Smith - 2014 - Scaling Collaborative Open Data Science(3).pdf:pdf},
title = {{Scaling Collaborative Open Data Science}},
year = {2014}
}
@article{Zheng2016,
abstract = {DevOps is an emerging concept and methodology for bridging the gap in the process of software development. At present, applying DevOps to data analytical system (DAS) is increasingly embraced. But the characteristics of this system, such as data protection, always leads to a series of constrains. It results in more difficulty of conducting DevOps on DAS.�Moreover, there are no DevOps solutions for reference. Therefore, exploring DevOps for DAS is valuable. In this paper, we illustrate DevOps demands of DAS from different perspectives, and constantly emphasize the importance of automation toolchain. Based on them, a process model for DAS DevOps (D2Ops) is proposed to clarify participants activities. In order to improve the efficiency, we attempt to integrate the automation toolchain. With the consideration of stability, six generic process components are designed to support this model. They can be the selection criteria for specific automation tools. We also present a reference facility based on these gene...},
author = {Zheng, Jiabin and Liu, Yan and Lin, Jin},
doi = {10.1142/S021819401640012X},
file = {:C$\backslash$:/Users/david/Dropbox/UNAL/2018-1/Tesis/IEEE Article/Segunda Busqueda/SLR/zheng2016.pdf:pdf},
issn = {9781891706394},
journal = {International Journal of Software Engineering and Knowledge Engineering},
keywords = {DevOps,automation tool,constraint,crosscutting concerns,data analytical system,process component},
number = {09n10},
pages = {1453--1472},
title = {{Exploring and Enabling DevOps for Data Analytical System with Essential Demands Elicitation}},
url = {http://www.worldscientific.com/doi/abs/10.1142/S021819401640012X},
volume = {26},
year = {2016}
}
@book{Jurney2017,
abstract = {Data science teams looking to turn research into useful analytics applications require not only the right tools, but also the right approach if they're to succeed. With the revised second edition of this hands-on guide, up-and-coming data scientists will learn how to use the Agile Data Science development methodology to build data applications with Python, Apache Spark, Kafka, and other tools.},
address = {Sebastopol},
author = {Jurney, Russell},
edition = {1 edition},
editor = {Cutt, Shannon},
file = {:C$\backslash$:/Users/david/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Jurney - 2017 - Agile Data Science 2.0(3).pdf:pdf},
issn = {978-1-491-96011-0},
pages = {352},
publisher = {O'Reilly Media},
title = {{Agile Data Science 2.0}},
volume = {1},
year = {2017}
}
@book{Stonebraker2018,
author = {Stonebraker, Mike and Bates-Haus, Nik and Cleary, Liam and Simmons, Larry},
file = {:C$\backslash$:/Users/david/Downloads/GDOR{\_}preview.pdf:pdf},
isbn = {978-1-492-03175-8},
publisher = {O'Reilly Media},
title = {{Getting Data Operations Right}},
url = {https://www.tamr.com/landing-pages/getting-data-operations-right/{\%}0A},
year = {2018}
}
@misc{Tamr2018,
author = {Tamr},
title = {{DataOps is Surging!}},
url = {https://www.tamr.com/dataops-is-surging/},
urldate = {2018-06-15},
year = {2018}
}
@article{FORSGREN2018,
abstract = {The article discusses the measuring of DevOps implemented in organizational contexts. Topics include the need to create a baseline for the measurement of DevOps, the use of system-based metrics, and characteristics of system data. The use of survey-based metrics is addressed in relation to software development and delivery.},
author = {FORSGREN, NICOLE and KERSTEN, M I K},
doi = {10.1145/3159169},
file = {:C$\backslash$:/Users/david/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/FORSGREN, KERSTEN - 2018 - DevOps Metrics.pdf:pdf},
issn = {00010782},
journal = {Communications of the ACM},
keywords = {Computer software development -- Evaluation,Computer systems,Data analysis,Organizational behavior,Software measurement},
number = {4},
pages = {44--48},
title = {{DevOps Metrics.}},
url = {http://search.ebscohost.com/login.aspx?direct=true{\&}db=bth{\&}AN=128730432{\&}site=ehost-live{\%}0A10.1145/3159169},
volume = {61},
year = {2018}
}
@article{Saltz2017,
author = {Saltz, Jeffrey S and Grady, Nancy W},
file = {:C$\backslash$:/Users/david/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Saltz, Grady - 2017 - The Ambiguity of Data Science Team Roles and the Need for a Data Science Workforce Framework.pdf:pdf},
isbn = {9781538627150},
keywords = {-big data,data,data science,project management},
pages = {2273--2279},
title = {{The Ambiguity of Data Science Team Roles and the Need for a Data Science Workforce Framework}},
year = {2017}
}
@incollection{Myrbakken2017,
abstract = {Process Improvement has been used for decades as a means to become better and more efficient. Whilst many organizations have used considerable resources for process improvement, investments in process improvement have not always led to changes and improvements expected. One most important aspects of management is to motivate the work force. However, management often fails to deliver. In fact, because management often uses extrinsic incentives to motivate their work force, it often ends up decreasing people's intrinsic motivation to work. The transformational moment has arrived where we need to re-think the traditional ways to foster engagement in process improvement. Gamification offers a solution for transformational change. By using game psychology and the principles of gamification it is possible to translate the traditional enthusiasm for play and social media engagement into the workplace as a basis for both succeeding with and accelerating the uptake of improvement. Gamification as a solution offers the opportunity for better user engagement, faster feedback of achievement and more visible progress indicators of process improvement. {\textcopyright} 2012 Springer-Verlag.},
author = {Myrbakken, H{\aa}vard and Colomo-Palacios, Ricardo},
doi = {10.1007/978-3-319-67383-7_2},
file = {:C$\backslash$:/Users/david/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Myrbakken, Colomo-Palacios - 2017 - DevSecOps A Multivocal Literature Review.pdf:pdf},
isbn = {978-3-319-67382-0},
issn = {18650929},
keywords = {iec 330xx process assessment,itil application {\'{a}} iso,standards series {\'{a}} design,tipa for,tipa framework {\'{a}} automation,{\'{a}} process assessment {\'{a}}},
number = {September},
pages = {17--29},
pmid = {21940323},
title = {{DevSecOps: A Multivocal Literature Review}},
url = {http://link.springer.com/10.1007/978-3-319-67383-7 http://link.springer.com/10.1007/978-3-319-67383-7{\_}2},
volume = {770},
year = {2017}
}
@article{B2016,
author = {B, Lucy Ellen Lwakatare and Kuvaja, Pasi and Oivo, Markku},
doi = {10.1007/978-3-319-49094-6},
file = {:C$\backslash$:/Users/david/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/B, Kuvaja, Oivo - 2016 - Product-Focused Software Process Improvement.pdf:pdf},
isbn = {978-3-319-49093-9},
keywords = {agile,continuous deployment,devops,effect,lean},
pages = {399--415},
title = {{Product-Focused Software Process Improvement}},
url = {http://link.springer.com/10.1007/978-3-319-49094-6},
volume = {10027},
year = {2016}
}
@article{QumerGill2018,
abstract = {{\textcopyright} 2018, Emerald Publishing Limited. Purpose: Development and operations (DevOps) is complex in nature. Organizations are unsure how to effectively establish a DevOps capability for the continuous delivery of information management systems. This paper aims to compile and analyze DevOps by applying the well-known systematic literature review (SLR) approach. This review is intended to provide a knowledge base to support the informed, effective and less risky adoption of DevOps for information management systems. Design/methodology/approach: In this qualitative research study, the SLR method was applied to identify 3,790 papers, of which, 32 relevant papers were selected and reviewed. Findings: The results are organized using the well-known ISO/IEC 24744 metamodel elements: people (roles), process, technology and artifacts. In total 11 major roles, 6 processes, 23 technologies, 5 artifacts and 7 challenges (including 6 corresponding solutions) were found. DevOps engineer is becoming a newly identified role. Continuous delivery pipeline and continuous improvement are the most highlighted major DevOps processes. Build system technology is becoming the key focus of DevOps. Finally, major challenges are around people and culture and the misunderstanding of DevOps. Potential research areas are: DevOps analytics, artifacts and tool–chain integration. Research limitations/implications: The research findings will serve as a resource for both practitioners and researchers who have interest in the research and adoption of DevOps for information management systems. Originality/value: This paper provides a comprehensive systematic review of the body of knowledge to support the ongoing research and adoption of emerging trends of DevOps for information management systems.},
author = {{Qumer Gill}, Asif and Loumish, Abhishek and Riyat, Isha and Han, Sungyoup},
doi = {10.1108/VJIKMS-02-2017-0007},
file = {:C$\backslash$:/Users/david/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Qumer Gill et al. - 2018 - DevOps for information management systems.pdf:pdf},
issn = {20595891},
journal = {VINE Journal of Information and Knowledge Management Systems},
keywords = {Challenges,Continuous delivery,Continuous deployment,DevOps,Information management systems},
number = {1},
pages = {122--139},
title = {{DevOps for information management systems}},
volume = {48},
year = {2018}
}
@misc{Valentine,
author = {Valentine, Crystal and Merchan, William},
file = {:C$\backslash$:/Users/david/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Valentine - Unknown - DataOps an Agile Methodology for Data-Driven Organizations(3).pdf:pdf},
title = {{DataOps: an Agile Methodology for Data-Driven Organizations}},
url = {https://mapr.com/whitepapers/datops-an-agile-methodology-for-data-driven-organizations/{\%}0A},
year = {2016}
}
@inproceedings{Zheng2016,
abstract = {DevOps is an emerging concept and methodology for bridging the gap in the process of software development. At present, applying DevOps to data analytical system (DAS) is increasingly embraced. But the characteristics of this system, such as data protection, always leads to a series of constrains. It results in more difficulty of conducting DevOps on DAS.�Moreover, there are no DevOps solutions for reference. Therefore, exploring DevOps for DAS is valuable. In this paper, we illustrate DevOps demands of DAS from different perspectives, and constantly emphasize the importance of automation toolchain. Based on them, a process model for DAS DevOps (D2Ops) is proposed to clarify participants activities. In order to improve the efficiency, we attempt to integrate the automation toolchain. With the consideration of stability, six generic process components are designed to support this model. They can be the selection criteria for specific automation tools. We also present a reference facility based on these gene...},
author = {Zheng, Jiabin and Liu, Yan and Lin, Jin},
booktitle = {International Journal of Software Engineering and Knowledge Engineering},
doi = {10.18293/SEKE2016-220},
file = {:C$\backslash$:/Users/david/Dropbox/UNAL/2018-1/Tesis/IEEE Article/Segunda Busqueda/SLR/seke16paper{\_}220.pdf:pdf},
issn = {9781891706394},
keywords = {DevOps,automation tool,constraint,crosscutting concerns,data analytical system,process component},
month = {jul},
number = {09n10},
pages = {255--260},
title = {{Exploring DevOps for Data Analytical System with Essential Demands Elicitation}},
url = {http://www.worldscientific.com/doi/abs/10.1142/S021819401640012X http://ksiresearchorg.ipage.com/seke/seke16paper/seke16paper{\_}220.pdf},
volume = {26},
year = {2016}
}
@book{Sarkar2018,
abstract = {Master the essential skills needed to recognize and solve complex problems with machine learning and deep learning. Using real-world examples that leverage the popular Python machine learning ecosystem, this book is your perfect companion for learning the art and science of machine learning to become a successful practitioner. The concepts, techniques, tools, frameworks, and methodologies used in this book will teach you how to think, design, build, and execute machine learning systems and projects successfully. Practical Machine Learning with Python follows a structured and comprehensive three-tiered approach packed with hands-on examples and code. Part 1 focuses on understanding machine learning concepts and tools. This includes machine learning basics with a broad overview of algorithms, techniques, concepts and applications, followed by a tour of the entire Python machine learning ecosystem. Brief guides for useful machine learning tools, libraries and frameworks are also covered. Part 2 details standard machine learning pipelines, with an emphasis on data processing analysis, feature engineering, and modeling. You will learn how to process, wrangle, summarize and visualize data in its various forms. Feature engineering and selection methodologies will be covered in detail with real-world datasets followed by model building, tuning, interpretation and deployment. Part 3 explores multiple real-world case studies spanning diverse domains and industries like retail, transportation, movies, music, marketing, computer vision and finance. For each case study, you will learn the application of various machine learning techniques and methods. The hands-on examples will help you become familiar with state-of-the-art machine learning tools and techniques and understand what algorithms are best suited for any problem. Practical Machine Learning with Python will empower you to start solving your own problems with machine learning today! What You'll Learn Execute end-to-end machine learning projects and systems Implement hands-on examples with industry standard, open source, robust machine learning tools and frameworks Review case studies depicting applications of machine learning and deep learning on diverse domains and industries Apply a wide range of machine learning models including regression, classification, and clustering. Understand and apply the latest models and methodologies from deep learning including CNNs, RNNs, LSTMs and transfer learning. Who This Book Is For IT professionals, analysts, developers, data scientists, engineers, graduate students},
author = {Sarkar, Dipanjan and Bali, Raghav and Sharma, Tushar},
doi = {10.1007/978-1-4842-3207-1},
file = {:C$\backslash$:/Users/david/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Sarkar, Bali, Sharma - 2018 - Practical Machine Learning with Python.pdf:pdf},
isbn = {978-1-4842-3207-1},
issn = {9781491964606},
pages = {530},
title = {{Practical Machine Learning with Python}},
url = {https://doi.org/10.1007/978-1-4842-3207-1},
year = {2018}
}
@inproceedings{Daihani,
abstract = {PT X is a joint venture subsidiary of a bank in Indonesia, which is a company, engaged in general insurance business. PT X is required to increase its share of the parent company by the shareholders in developing its business potential. In developing the potential of the business, companies need enough information to be analyzed further. Sources of information that can be used is the business data of the company, both of PT X as a subsidiary and its holding company. By utilizing business data in large numbers, the company will find a variety of information needed. For the business data processing required a technique of data mining. In a study conducted, the implementation of the model refers to the six stages of Cross-Industry Standard Process for Data Mining or commonly known by the acronym CRISP-DM. In doing data mining, the six phases of the CRISP-DM is business understanding, understanding the data, the data preparation, modeling, evaluation, and deployment. At this stage of deployment, the report will be made by the customer segmentation by region. The expected result is the information required in the form of a new customer pipeline.},
author = {Daihani, Dadan Umar and Feblian, Dina},
booktitle = {Proceeding of 9th International Seminar on Industrial Engineering and Management},
file = {:C$\backslash$:/Users/david/Dropbox/UNAL/2018-1/Tesis/DevOps - State of the Art/Refrences/CRISP-DM/9th{\_}ISIEM{\_}2016{\_}paper{\_}59{\_}dss.pdf:pdf},
title = {{IMPLEMENTATION OF CRISP-DM MODEL IN ORDER TO DEFINE THE SALES PIPE LINES OF PT X}},
year = {2016}
}
@misc{Hecht2017a,
author = {Hecht, Lawrence},
booktitle = {The NewStack},
keywords = {Blue Hill Research,Continuous Integration and Deployment,Data,Data Analysis,DataOps,Talend,big data,data engineering,developers,devops,operations,operations management,rocana,the new stack analysts},
title = {{What is ‘DataOps' and Why It Matters}},
url = {https://thenewstack.io/delving-dataops-matters/?utm{\_}content=buffer57f30{\&}utm{\_}medium=social{\&}utm{\_}source=twitter.com{\&}utm{\_}campaign=buffer},
urldate = {2018-06-18},
year = {2017}
}
@article{DeBayser2015,
abstract = {DevOps (a portmanteau of “development” and “operations”) is a software development method that extends the agile philosophy to rapidly produce software products and services and to improve operations performance and quality assurance. It was born to accelerate the delivery of web-based systems and quickly bring new value to users. Many web-based systems evolve according to usage trends without a clear long-term goal. Before the widespread use of web services, most software with a clear goal were delivered as packages that users installed on their own system. New versions were delivered with a much lower frequency, with periods in between versions ranging from months to years. Development cycles were divided into large design, coding and testing phases culminating in the release of a new stable version. In software development in the context of applied science, even when the goal is clear, the process to attain it is not. Hence, working releases that capture the current software state must be released frequently in order to reduce the risks for all stakeholders and to make it possible to assess the current state of a project and steer it in the right direction. This paper explores the usefulness of DevOps concepts to improve the development of software that supports scientific projects. We establish the similarities and differences between scientific projects and web applications development, and discuss where the related methodologies need to be extended. Unique challenges are discussed herewith developed solutions, and still open questions. Lessons learned are highlighted as best practices to be followed in research projects. This discussion is rooted in our experience in real-life projects at the IBM Research Brazil Lab, which just as well apply to other research institutions.},
author = {{De Bayser}, Maximilien and Azevedo, Leonardo G. and Cerqueira, Renato},
doi = {10.1109/INM.2015.7140503},
isbn = {9783901882760},
issn = {1573-0077},
journal = {Proceedings of the 2015 IFIP/IEEE International Symposium on Integrated Network Management, IM 2015},
pages = {1398--1404},
title = {{ResearchOps: The case for DevOps in scientific applications}},
year = {2015}
}
@article{Staples2016,
abstract = {From a future history of 2025: Continuous development is common for build/test (continuous integration) and operations (devOps). This trend continues through the lifecycle, into what we call 'devUsage': continuous usage validation. In addition to ensuring systems meet user needs, organisations continuously validate their legal and ethical use. The rise of end-user programming and multi-sided platforms exacerbate validation challenges. A separate trend is the specialisation of software engineering for technical domains, including data analytics. This domain has specific validation challenges. We must validate the accuracy of statistical models, but also whether they have illegal or unethical biases. Usage needs addressed by machine learning are sometimes not specifiable in the traditional sense, and statistical models are often 'black boxes'. We describe future research to investigate solutions to these devUsage challenges for data analytics systems. We will adapt risk management and governance frameworks previously used for software product qualities, use social network communities for input from aligned stakeholder groups, and perform cross-validation using autonomic experimentation, cyber-physical data streams, and online discursive feedback. {\textcopyright} 2016 ACM.},
author = {Staples, Mark and Zhu, Liming and Grundy, John},
doi = {10.1145/2889160.2889207},
isbn = {9781450342056},
issn = {02705257},
journal = {Proceedings of the 38th International Conference on Software Engineering Companion - ICSE '16},
keywords = {2025,as future history from,chine learning,continuous development,data analytics,devops,ethics,governance,ma-,software validation,this paper is written,to avoid},
pages = {769--772},
title = {{Continuous validation for data analytics systems}},
url = {http://dl.acm.org/citation.cfm?doid=2889160.2889207},
year = {2016}
}
@article{Fitzgerald2014,
abstract = {Throughout its short history, software development has been characterized by harmful disconnects between important activities e.g., planning, development and implementation. The problem is further exacerbated by the episodic and infrequent performance of activities such as planning, testing, integration and releases. Several emerging phenomena reflect attempts to address these problems. For example, the Enterprise Agile concept has emerged as a recognition that the benefits of agile software development will be sub- optimal if not complemented by an agile approach in related organizational function such as finance and HR. Continuous integration is a practice which has emerged to eliminate discontinuities between development and deployment. In a similar vein, the recent emphasis on DevOps recognizes that the integration between software development and its operational deployment needs to be a continuous one. We argue a similar continuity is required between business strategy and development, BizDev being the term we coin for this. These disconnects are even more problematic given the need for reliability and resilience in the complex and data-intensive systems being developed today. Drawing on the lean concept of flow, we identify a number of continuous activities which are important for software development in today's context. These activities include continuous planning, continuous integration, continuous deployment, continuous delivery, continuous verification, continuous testing, continuous compliance,continuous security, continuous use, continuous trust, continuous run-time monitoring, continuous improvement (both process and product), all underpinned by continuous innovation. We use the umbrella term, ``Continuous *'' (continuous star) to identify this family of continuous activities.},
author = {Fitzgerald, Brian and Stol, Klaas-Jan},
doi = {10.1145/2593812.2593813},
isbn = {9781450328562},
journal = {Proceedings of the 1st International Workshop on Rapid Continuous Software Engineering - RCoSE 2014},
keywords = {bizdev,continuous software engi-,continuous star,devops},
pages = {1--9},
title = {{Continuous software engineering and beyond: trends and challenges}},
url = {http://dl.acm.org/citation.cfm?doid=2593812.2593813},
year = {2014}
}
@misc{Dezyre2016,
author = {Dezyre},
title = {{Life Cycle of a Data Science Project}},
url = {https://www.dezyre.com/article/life-cycle-of-a-data-science-project/270},
urldate = {2018-04-07},
year = {2016}
}
@article{Chen2015,
abstract = {Ch15a},
author = {Chen, Lianping},
doi = {10.1109/WICSA.2015.23},
isbn = {9781479919222},
journal = {Proceedings - 12th Working IEEE/IFIP Conference on Software Architecture, WICSA 2015},
keywords = {DevOps,architecturally significant requirements,continuous delivery,continuous deployment,continuous software engineering,non-functional requirements,quality attributes,software architecture},
pages = {131--134},
title = {{Towards Architecting for Continuous Delivery}},
year = {2015}
}
@article{Shahin2015,
abstract = {Development and Operations (DevOps) in the context of Continuous Deployment (CD) have emerged as an attractive software development movement, which tries to establish a strong connection between development and operations teams. CD is defined as the ability to quickly put new releases into production. We believe that DevOps/CD brings new challenges for architects, which considerably impacts both on their (architectural) design decisions and their organizational responsibilities. We assert that there is an important and urgent need of sufficient research work to gain a deep understanding of how DevOps/CD adoption can influence architecting, architectural decision-making processes and their outcomes in an organization. This PhD research is aimed at understanding and addressing new challenges for designing architectures for supporting DevOps in the context of CD.},
author = {Shahin, Mojtaba},
doi = {10.1145/2811681.2824996},
isbn = {9781450337960},
issn = {9781450337960},
journal = {Proceedings of the ASWEC 2015 24th Australasian Software Engineering Conference on - ASWEC ' 15 Vol. II},
pages = {147--148},
title = {{Architecting for DevOps and Continuous Deployment}},
url = {http://dl.acm.org/citation.cfm?doid=2811681.2824996},
year = {2015}
}
@misc{Garzas2015a,
author = {Garzas, Javier and Morales, Maria and Fern{\'{a}}ndez, Carlos Manuel},
booktitle = {Byte},
title = {{DevOps: rompiendo las barreras entre desarrollo y operaciones bajo el marco de la agilidad, la ISO 20000 y la ISO 15504/12207 - Revista Byte TI}},
url = {https://www.revistabyte.es/tendencias-byte-ti/devops-rompiendo-las-barreras-entre-desarrollo-y-operaciones-bajo-la-el-marco-de-la-agilidad-la-iso-20000-y-la-iso-1550412207/},
urldate = {2018-03-30},
year = {2015}
}
@misc{Humble,
author = {Humble, Jezz},
title = {{DevOps Manifesto}},
url = {https://sites.google.com/a/jezhumble.net/devops-manifesto/},
urldate = {2018-03-23}
}
@misc{Beedle2001,
author = {Beedle, Mike},
title = {{Manifesto for Agile Software Development}},
url = {http://agilemanifesto.org/},
urldate = {2018-04-23},
year = {2001}
}
@book{Chapman2000,
abstract = {This document describes the CRISP-DM process model and contains information about the CRISP-DM methodology, the CRISP-DM reference model, the CRISP-DM user guide, and the CRISP-DM reports, as well as an appendix with additional related information. This document and information herein are the exclusive property of the partners of the CRISP-DM consortium: NCR Systems Engineering Copenhagen (USA and Denmark), DaimlerChrysler AG (Germany), SPSS Inc. (USA), and OHRA Verzekeringen en Bank Groep B.V. (The Netherlands).},
author = {Chapman, Pete and Clinton, Julian},
file = {:C$\backslash$:/Users/david/Dropbox/UNAL/2018-1/Tesis/DevOps - State of the Art/Refrences/CRISP-DM/cRISP-DM .pdf:pdf},
publisher = {SPSS},
title = {{CRISP-DM 1.0 Step-by-step}},
year = {2000}
}
@book{Humble2010a,
abstract = {One of the major aims of this book is to improve collaboration between the people responsible for delivering software. In particular, we have in mind developers, testers, systems and database administrators, and managers. We cover topics from traditional configuration management, source code control, release planning, auditing, compliance, and integration to the automation of your building, testing, and deployment processes. We also describe techniques such as automated acceptance testing, dependency management, database migration, and the creation and management of testing and production environments. Many people involved in creating software consider these activities secondary to writing code. However, in our experience they take up a great deal of time and effort, and are critical to successful software delivery. When the risks surrounding these activities are not managed adequately, they can end up costing a lot of money, often more than the cost of building the software in the first place.},
author = {Humble, Jezz and Farley, David},
booktitle = {Continuous delivery},
doi = {10.1007/s13398-014-0173-7.2},
file = {:C$\backslash$:/Users/david/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Humble, Farley - 2010 - Continuous Delivery Reliable Software Releases through Build, Test, and Deployment Automation.pdf:pdf},
isbn = {978-0-321-60191-9},
issn = {1098-6596},
pages = {497},
pmid = {25246403},
title = {{Continuous Delivery: Reliable Software Releases through Build, Test, and Deployment Automation}},
year = {2010}
}
@book{Swartout2014,
author = {Swartout, Paul},
edition = {second},
isbn = {9781784399313},
pages = {196},
publisher = {Packt Publishing Ltd},
title = {{Continuous Delivery and DevOps – A Quickstart Guide}},
year = {2014}
}
@book{Verona2016,
author = {Verona, Joakim},
isbn = {9781785882876},
publisher = {Packt Publishing Ltd.},
title = {{Practical DevOps}},
year = {2016}
}
@book{Ravichandran2016,
abstract = {This book provides digital leaders who are accountable for the rapid development of high-quality software applications a concise guide to designing, implementing, measuring, and improving DevOps programs that are tailored to their organizations.In DevOps for Digital Leaders, deep collective experience on both sides of the dev–ops divide informs the global thought leadership and penetrating insights of the authors, all three of whom are cross-portfolio DevOps leaders at CA Technologies. Aruna Ravichandran, Kieran Taylor, and Peter Waterhouse analyze the organizational benefits, costs, freedoms, and constraints of DevOps. They chart the coordinated strategy of organizational change, metrics, lean thinking, and investment that an enterprise must undertake to realize the full potential of DevOps and reach the sweet spot where accelerating code deployments drive increasing customer satisfaction, revenue, and profitability. Digital leaders are charged to bridge the dev–ops disconnect if their organizations are to survive and flourish in a business world increasingly differentiated by the degree to which dynamic application software development harmonizes with operational resilience and reliability. This short book applies the DevOps perspective to the competitive challenge, faced by every high-performance IT organization today, of integrating and automating open source, cloud, and enterprise tools, processes, and techniques across the software development life cycle from requirements to release},
address = {Berkeley, CA},
author = {Ravichandran, Aruna and Taylor, Kieran and Waterhouse, Peter},
doi = {10.1007/978-1-4842-1842-6},
isbn = {978-1-4842-1841-9},
publisher = {Apress},
title = {{DevOps for Digital Leaders}},
url = {http://link.springer.com/10.1007/978-1-4842-1842-6},
year = {2016}
}
@book{Sacks2012,
address = {Berkeley, CA},
author = {Sacks, Matthew},
doi = {10.1007/978-1-4302-3970-3},
isbn = {978-1-4302-3969-7},
publisher = {Apress},
title = {{Pro Website Development and Operations}},
url = {http://link.springer.com/10.1007/978-1-4302-3970-3},
year = {2012}
}
@book{Davis2016,
author = {Davis, Jennifer and Daniels, Katherine},
isbn = {9781491926307},
keywords = {DevOps},
mendeley-tags = {DevOps},
publisher = {O'Reilly Media},
title = {{Effective DevOps}},
year = {2016}
}
@techreport{Brown2016,
abstract = {The fifth annual State of DevOps Report confirms and highlights the fact that achieving higher IT and organizational performance is a team effort spanning development and operations — and it's an investment that can deliver powerful returns. This year's report shows how improving the entire product lifecycle — from initial product planning, to quality and security assurance, to customer feedback — speeds up delivery while improving quality, security and business outcomes. DevOps practices also improve organizational culture and enhance employee engagement.},
author = {Brown, Alanna and Forsgren, Nicole and Humble, Jez},
pages = {31},
title = {{2016 State of DevOps Report}},
url = {https://www.ciosummits.com/Online{\_}Assets{\_}Puppet{\_}2016{\_}State{\_}of{\_}DevOps{\_}Report.pdf},
year = {2016}
}
@techreport{PuppetLabs2015,
abstract = {The fourth annual State of DevOps Survey confirms that IT performance provides real business value. High-performing IT organizations have a strong and positive impact on the overall performance of the organizations they serve.},
author = {{Puppet Labs}},
booktitle = {The Journal of Prosthetic Dentistry},
doi = {10.1016/S0022-3913(12)00047-9},
isbn = {066012128X},
issn = {00223913},
month = {may},
title = {{2015 State of DevOps Report}},
url = {http://puppetlabs.com/2015-devops-report http://linkinghub.elsevier.com/retrieve/pii/S0022391312000479},
year = {2015}
}
@article{Ebert2016,
abstract = {Building on lean and agile practices, DevOps means end-to-end automation in software development and delivery. Hardly anybody will be able to approach it with a cookbook-style approach, but most developers will benefit from better connecting the previously isolated silos of development and operations. Many DevOps tools exist that can help them do this.},
author = {Ebert, Christof and Gallardo, Gorka and Hernantes, Josune and Serrano, Nicolas},
doi = {10.1109/MS.2016.68},
isbn = {0903458950},
issn = {07407459},
journal = {IEEE Software},
keywords = {AWS,Amazon Web Services,Ansible,Bamboo,Cacti,Chef,DevOps,Gradle,Graylog2,Jenkins,Logging,Loggly,Maven,Nagios,New Relic,Puppet,TeamCity,apache Ant,configuration management,continuous integration,microservices,software development,software engineering},
number = {3},
pages = {94--100},
title = {{DevOps}},
volume = {33},
year = {2016}
}
@book{Huttermann2012,
address = {Berkeley, CA},
author = {H{\"{u}}ttermann, Michael},
doi = {10.1007/978-1-4302-4570-4},
isbn = {978-1-4302-4569-8},
pages = {184},
publisher = {Apress},
title = {{DevOps for Developers}},
url = {http://link.springer.com/10.1007/978-1-4302-4570-4},
year = {2012}
}
@techreport{Szalvay2004,
author = {Szalvay, Victor},
booktitle = {Danube Technologies, Inc., Bellevue, WA},
institution = {Danube Technologies, Inc},
mendeley-groups = {Documentos/Tesis/DevOps,Documentos/Tesis/Bibliografia},
number = {November},
title = {{An introduction to Agile software development}},
url = {http://www.danube.com/docs/Intro{\_}to{\_}Agile.pdf},
year = {2004}
}


@book{Duffy2015,
author = {Duffy, Michael},
isbn = {978-1-78439-282-6},
publisher = {Packt Publishing Ltd},
title = {{DevOps Automation Cookbook}},
year = {2015}
}
@book{Bass2015,
author = {Bass, Len and Weber, Ingo and Zhu, Liming},
isbn = {978-0-13-404984-7},
publisher = {Addison-Wesley Professional},
title = {{DevOps: A Software Architect's Perspective}},
year = {2015}
}
@book{Humble2011,
author = {Humble, Jez and Farley, David},
isbn = {9780321601919},
publisher = {Pearson Education},
title = {{Continuous Delivery}},
year = {2011}
}
@techreport{Datascience,
author = {DataScience},
title = {{Open Source Tools for Enterprise Data Science}},
year = {2017}
}
@article{Grossman2016,
abstract = {Data commons collocate data, storage, and computing infrastructure with core services and commonly used tools and applications for managing, analyzing, and sharing data to create an interoperable resource for the research community. An architecture for data commons is described, as well as some lessons learned from operating several large-scale data commons.},
author = {Grossman, Robert L and Heath, Allison and Murphy, Mark and Patterson, Maria and Wells, Walt},
doi = {10.1109/MCSE.2016.92},
issn = {9789881404718},
journal = {Computing in Science and Engineering},
keywords = {cloud computing,data as a service,data commons,science as a service,scientific computing,software as services},
number = {5},
pages = {10--20},
title = {{A case for data commons: Toward data science as a service}},
volume = {18},
year = {2016}
}
@misc{,
title = {{The DataOps Manifesto}},
url = {http://dataopsmanifesto.org/}
}
@book{IBM1994,
author = {IBM},
file = {:C$\backslash$:/Users/david/Dropbox/UNAL/2018-1/Tesis/DevOps - State of the Art/Refrences/CRISP-DM/CRISP-DM.pdf:pdf},
pages = {47},
title = {{Manual CRISP-DM de IBM SPSS Modeler}},
year = {1994}
}
@misc{Vorhies2017,
author = {Vorhies, William},
title = {{DataOps – It's a Secret}},
url = {https://www.datasciencecentral.com/profiles/blogs/dataops-it-s-a-secret},
year = {2017}
}
@inproceedings{Demchenko2016,
abstract = {This paper describes the general architecture and functional components of the cloud based Big Data Infrastructure (BDI). The proposed BDI architecture is based on the analysis of the emerging Big Data and data intensive technologies and supported by the definition of the Big Data Architecture Framework (BDAF) that defines the following components of the Big Data technologies: Big Data definition, Data Management including data lifecycle and data structures, Big Data Infrastructure (generically cloud based), Data Analytics technologies and platforms, and Big Data security, compliance and privacy. The paper provides example of requirements analysis and implementation of two bioinformatics use cases on cloud and using SlipStream based cloud applications deployment and management automation platform being developed in the CYCLONE project. The paper also refers to importance of standardisation of all components of BDAF and BDI and provides short overview of the NIST Big Data Interoperability Framework (BDIF). The paper discusses importance of automation of all stages of the Big Data applications developments, deployment and management and refers to existing cloud automation tools and new developments in the SlipStream cloud automation platform that allows multi-cloud applications deployment and management.},
author = {Demchenko, Yuri and Turkmen, Fatih and de Laat, Cees and Blanchet, Christophe and Loomis, Charles},
booktitle = {2016 International Conference on High Performance Computing {\&} Simulation (HPCS)},
doi = {10.1109/HPCSim.2016.7568394},
isbn = {978-1-5090-2088-1},
month = {jul},
pages = {628--636},
publisher = {IEEE},
title = {{Cloud based big data infrastructure: Architectural components and automated provisioning}},
url = {http://ieeexplore.ieee.org/document/7568394/},
year = {2016}
}
@article{Londono2014,
abstract = {Gu{\'{i}}a para construir estados del arte.},
author = {Londo{\~{n}}o, Olga Lucia and Maldonado, Luis Facundo and Calder{\'{o}}n, Liccy Catalina},
doi = {10.5672/apunts.2014-0983.es.(2012/1).107.10},
journal = {International Corporation of Networks of Knowledge},
pages = {1--39},
title = {{Gu{\'{i}}a para construir estados del arte}},
year = {2014}
}
@book{Chambers2017,
author = {Chambers, Michele and Doig, Christine and Stokes-Rees, Ian},
isbn = {9781491972991},
title = {{Breaking Data Science Open}},
year = {2017}
}
@misc{Bailey2015,
author = {Bailey, Jason},
title = {{From DevOps to DataOps}},
url = {https://www.datasciencecentral.com/profiles/blogs/from-devops-to-dataops},
year = {2015}
}
@article{Wu2016,
abstract = {Many real-world data analysis scenarios require pipelining and integration of multiple (big) data-processing and data-analytics jobs, which often execute in heterogeneous environments, such as MapReduce; Spark; or R, Python, or Bash scripts. Such a pipeline requires much glue code to get data across environments. Maintaining and evolving these pipelines are difficult. Pipeline frameworks that try to solve such problems are usually built on top of a single environment. They might require rewriting the original job to take into account a new API or paradigm. The Pipeline61 framework supports the building of data pipelines involving heterogeneous execution environments. It reuses the existing code of the deployed jobs in different environments and provides version control and dependency management that deals with typical software engineering issues. A real-world case study shows its effectiveness. This article is part of a special issue on Software Engineering for Big Data Systems.},
author = {Wu, Dongyao and Zhu, Liming and Xu, Xiwei and Sakr, Sherif and Sun, Daniel and Lu, Qinghua},
doi = {10.1109/MS.2016.35},
issn = {0740-7459 VO - 33},
journal = {IEEE Software},
keywords = {MapReduce,Pipeline61,Spark,big data,pipeline,software development,software engineering},
number = {2},
pages = {60--67},
title = {{Building pipelines for heterogeneous execution environments for big data processing}},
volume = {33},
year = {2016}
}
@misc{DataKitchen2017,
author = {DataKitchen},
title = {{2017: The Year of DataOps}},
url = {https://medium.com/data-ops/2017-the-year-of-dataops-b2023c17d2af},
year = {2017}
}
@misc{Palmer2015,
author = {Palmer, Andy},
booktitle = {Tamr},
title = {{From DevOps to DataOps, By Andy Palmer - Tamr Inc.}},
url = {https://www.tamr.com/from-devops-to-dataops-by-andy-palmer/},
year = {2015}
}
@article{Paakkonen2015,
abstract = {Many business cases exploiting big data have been realised in recent years; Twitter, LinkedIn, and Facebook are examples of companies in the social networking domain. Other big data use cases have focused on capturing of value from streaming of movies (Netflix), monitoring of network traffic, or improvement of processes in the manufacturing industry. Also, implementation architectures of the use cases have been published. However, conceptual work integrating the approaches into one coherent reference architecture has been limited. The contribution of this paper is technology independent reference architecture for big data systems, which is based on analysis of published implementation architectures of big data use cases. An additional contribution is classification of related implementation technologies and products/services, which is based on analysis of the published use cases and survey of related work. The reference architecture and associated classification are aimed for facilitating architecture design and selection of technologies or commercial solutions, when constructing big data systems.},
author = {P{\"{a}}{\"{a}}kk{\"{o}}nen, Pekka and Pakkala, Daniel},
doi = {10.1016/j.bdr.2015.01.001},
issn = {978-1-4799-6023-1},
journal = {Big Data Research},
keywords = {Big data,Classification,Literature survey,Reference architecture},
number = {4},
pages = {166--186},
publisher = {Elsevier Inc.},
title = {{Reference Architecture and Classification of Technologies, Products and Services for Big Data Systems}},
url = {http://dx.doi.org/10.1016/j.bdr.2015.01.001},
volume = {2},
year = {2015}
}
@techreport{Hagerty2016,
author = {Hagerty, John},
number = {October 2016},
title = {{2017 Planning Guide for Data and Analytics}},
url = {https://www.gartner.com/document/3810464?ref=TrackDBDTextEmail{\&}refval=1506952807250},
year = {2016}
}
@techreport{Jain2017,
author = {Jain, Kunal},
title = {{Analytics Industry Report 2017}},
url = {https://www.jigsawacademy.com/wp-content/uploads/2017/05/Jigsaw-Academy-Analytics-Industry-Report-2017.pdf},
year = {2017}
}
@article{Larson2016a,
abstract = {Agile methodologies were introduced in 2001. Since this time, practitioners have applied Agile methodologies to many delivery disciplines. This article explores the application of Agile methodologies and principles to business intelligence delivery and how Agile has changed with the evolution of business intelligence. Business intelligence has evolved because the amount of data generated through the internet and smart devices has grown exponentially altering how organizations and individuals use information. The practice of business intelligence delivery with an Agile methodology has matured; however, business intelligence has evolved altering the use of Agile principles and practices. The Big Data phenomenon, the volume, variety, and velocity of data, has impacted business intelligence and the use of information. New trends such as fast analytics and data science have emerged as part of business intelligence. This paper addresses how Agile principles and practices have evolved with business intelligence, as well as its challenges and future directions.},
author = {Larson, Deanne and Chang, Victor},
doi = {10.1016/j.ijinfomgt.2016.04.013},
issn = {02684012},
journal = {International Journal of Information Management},
keywords = {Agile methodologies,Analytics and big data,Business intelligence (BI),Lifecycle for BI and Big Data},
number = {5},
pages = {700--710},
publisher = {Elsevier Ltd},
title = {{A review and future direction of agile, business intelligence, analytics and data science}},
url = {http://dx.doi.org/10.1016/j.ijinfomgt.2016.04.013},
volume = {36},
year = {2016}
}
@misc{Taylor2017,
abstract = {CRISP-DM is the leading approach for managing data mining, predictive analytic and data science projects. CRISP-DM is effective but many analytic projects neglect key elements of the approach. },
author = {Taylor, James},
booktitle = {KDnuggets},
title = {{Four Problems in Using CRISP-DM and How To Fix Them}},
url = {https://www.kdnuggets.com/2017/01/four-problems-crisp-dm-fix.html},
year = {2017}
}
@article{Vaasanthi2017,
author = {Vaasanthi, R and Kingston, S Philip and Kumari, V Prasanna},
journal = {International Journal of Computer Applications},
number = {11},
pages = {47--49},
title = {{Analysis of Devops Tools using the Traditional Data Mining Techniques}},
volume = {161},
year = {2017}
}
@misc{Gartner,
author = {Gartner},
title = {{Data Ops - Gartner IT Glossary}},
url = {https://www.gartner.com/it-glossary/data-ops}
}
@misc{Swanson2017,
author = {Swanson, Brittany-Marie},
title = {{Q{\&}A: How to Use DevOps for Data Science}},
url = {https://www.datascience.com/blog/devops-data-science},
year = {2017}
}
@misc{Piatetsky2014,
abstract = {CRISP-DM remains the most popular methodology for analytics, data mining, and data science projects, with 43{\%} share in latest KDnuggets Poll, but a replacement for unmaintained CRISP-DM is long overdue. },
author = {Piatetsky, Gregory},
booktitle = {KDnuggets},
title = {{CRISP-DM, still the top methodology for analytics, data mining, or data science projects}},
url = {https://www.kdnuggets.com/2014/10/crisp-dm-top-methodology-analytics-data-mining-data-science-projects.html},
year = {2014}
}
@article{Chen2016a,
abstract = {Agile development for big data analytics has become the new normal. However, research questions remain: 1) how should a big data system be designed and developed to effectively support advanced analytics? and 2) how should the agile process be adapted for big data analytics development? This article contributes an Architecture-centric Agile Big data Analytics (AABA) development methodology evolved and validated in 10 case studies through Collaborative Practice Research. Our studies showed that architecture agility is the key for successful agile big data analytics development. Employing an architecture-centric approach, the AABA methodology integrates the Big Data system Design (BDD) method and Architecture-centric Agile Analytics with architecture-supported DevOps (AAA) model for effective value discovery and rapid continuous delivery of value. The uses of a design concepts catalog and architectural spikes are advancements to architecture design methods that have proven to be critical to agile big data analytics development.},
author = {Chen, Hong Mei and Kazman, Rick and Haziyev, Serge},
doi = {10.1109/HICSS.2016.665},
file = {:C$\backslash$:/Users/david/Dropbox/UNAL/2018-1/Tesis/IEEE Article/Segunda Busqueda/SLR/chen2016{\_}1.pdf:pdf},
issn = {9780769556703},
journal = {Proceedings of the Annual Hawaii International Conference on System Sciences},
keywords = {Agile devleopment methodology,Big data and analytics,Big data design method,Software architecture},
pages = {5378--5387},
title = {{Agile big data analytics development: An architecture-centric approach}},
volume = {2016-March},
year = {2016}
}
@article{Laukkanen2017,
abstract = {Context: Continuous delivery is a software development discipline in which software is always kept releasable. The literature contains instructions on how to adopt continuous delivery, but the adoption has been challenging in practice. Objective: In this study, a systematic literature review is conducted to survey the faced problems when adopting continuous delivery. In addition, we identify causes for and solutions to the problems. Method: By searching five major bibliographic databases, we identified 293 articles related to continuous delivery. We selected 30 of them for further analysis based on them containing empirical evidence of adoption of continuous delivery, and focus on practice instead of only tooling. We analyzed the selected articles qualitatively and extracted problems, causes and solutions. The problems and solutions were thematically synthesized into seven themes: build design, system design, integration, testing, release, human and organizational and resource. Results: We identified a total of 40 problems, 28 causal relationships and 29 solutions related to adoption of continuous delivery. Testing and integration problems were reported most often, while the most critical reported problems were related to testing and system design. Causally, system design and testing were most connected to other themes. Solutions in the system design, resource and human and organizational themes had the most significant impact on the other themes. The system design and build design themes had the least reported solutions. Conclusions: When adopting continuous delivery, problems related to system design are common, critical and little studied. The found problems, causes and solutions can be used to solve problems when adopting continuous delivery in practice.},
author = {Laukkanen, Eero and Itkonen, Juha and Lassenius, Casper},
doi = {10.1016/j.infsof.2016.10.001},
issn = {09505849},
journal = {Information and Software Technology},
keywords = {Continuous delivery,Continuous deployment,Continuous integration,Systematic literature review},
pages = {55--79},
publisher = {Elsevier B.V.},
title = {{Problems, causes and solutions when adopting continuous delivery—A systematic literature review}},
volume = {82},
year = {2017}
}
@article{Jabbari2016,
abstract = {Context: DevOps, the combination of Development and Operations, is a new way of thinking in the software engi-neering domain that recently received much attention. Given that DevOps is a new term and novel concept recently in-troduced, no common understanding of what it entails has been achieved yet. Consequently, definitions of DevOps of-ten only represent a part that is relevant to the concept. Objective:This study aims to characterize DevOps by ex-ploring central components of DevOps definitions reported in the literature, specifying practices explicitly proposed for DevOps and investigating the similarities and differences be-tween DevOps and other existing methods in software engi-neering. Method: A systematic mapping study was conducted that used six electronic databases: IEEE, ACM, Inspec, Sco-pus, Wiley Online Library and Web of Science. Result: 44 studies have been selected that report a defi-nition of DevOps, 15 studies explicitly stating DevOps prac-tices, and 15 studies stating how DevOps is related to other existing methods. Papers in some cases stated a combina-tion of a definition, practices, and relations to other meth-ods, the total number of primary studies was 49. Conclusion: We proposed a definition for DevOps which may overcome inconsistencies over the various existing defi-nitions of individual research studies. In addition, the prac-tices explicitly proposed for DevOps have been presented as well as the relation to other software development methods.},
author = {Jabbari, Ramtin and bin Ali, Nauman and Petersen, Kai and Tanveer, Binish},
doi = {10.1145/2962695.2962707},
isbn = {9781450341349},
issn = {07421222},
journal = {Proceedings of the Scientific Workshop Proceedings of XP2016 on - XP '16 Workshops},
keywords = {devops definition,devops practice,software development},
pages = {1--11},
title = {{What is DevOps? A Systematic Mapping Study on Definitions and Practices}},
url = {http://dl.acm.org/citation.cfm?doid=2962695.2962707},
year = {2016}
}
@article{Virmani2015,
abstract = {Vi15b},
author = {Virmani, Manish},
doi = {10.1109/INTECH.2015.7173368},
isbn = {9781467375504},
journal = {5th International Conference on Innovative Computing Technology, INTECH 2015},
keywords = {Continuous Delivery,Continuous Integration,DevOps,Infrastructure as a Code (IAAC)},
number = {Intech},
pages = {78--82},
title = {{Understanding DevOps {\&} bridging the gap from continuous integration to continuous delivery}},
year = {2015}
}
@book{Rangel2015,
author = {Rangel, Derek},
file = {:C$\backslash$:/Users/david/Dropbox/UNAL/2018-1/Tesis/DevOps - State of the Art/Refrences/DevOps/DevOps.pdf:pdf},
pages = {90},
publisher = {CreateSpace Independent Publishing Platform},
title = {{DevOps: Learn One of the Most Powerful Software Development Methodologies FAST AND EASY!}},
year = {2015}
}
@article{Erich2017,
abstract = {Background: software engineering research (SE) lacks theory and methodologies for addressing human aspects in software development. Development tasks are undertaken through cognitive processing activities. Affects (emotions, moods, feelings) have a linkage to cognitive processing activities and the productivity of individuals. SE research needs to incorporate affect measurements to valorize human factors and to enhance management styles. Objective: analyze the affects dimensions of valence, arousal, and dominance of software developers and their real-time correlation with their self-assessed productivity (sPR). Method: repeated measurements design with 8 participants (4 students, 4 professionals), conveniently sampled and studied individually over 90 minutes of programming. The analysis was performed by fitting a linear mixed- effects (LME) model. Results: valence and dominance are positively correlated with the sPR. The model was able to express about 38{\%} of deviance from the sPR. Many lessons were learned when employing psychological measurements in SE and for fitting LME. Conclusion: this article demonstrates the value of applying psychological tests in SE and echoes a call to valorize the human, individualized aspects of software developers. It reports a body of knowledge about affects, their classification, their measurement, and the best practices to perform psychological measurements in SE with LME models.},
archivePrefix = {arXiv},
arxivId = {1408.1293},
author = {Erich, F. M.A. and Amrit, C. and Daneva, M.},
doi = {10.1002/smr.1885},
eprint = {1408.1293},
isbn = {9781450330565},
issn = {20477481},
journal = {Journal of Software: Evolution and Process},
keywords = {DevOps,agile software development,empirical study,qualitative interviews,software development life cycle,systematic literature review},
number = {6},
pages = {1--20},
pmid = {67195556},
title = {{A qualitative study of DevOps usage in practice}},
volume = {29},
year = {2017}
}
@article{Erich2014,
abstract = {DevOps is a conceptual framework for reintegrating development and operations of Information Systems. We performed a Systematic Mapping Study to explore DevOps. 26 articles out of 139 were selected, studied and summarized. Based on this a concept table was constructed. We discovered that DevOps has not been adequately studied in scientific literature. There is relatively little research available on DevOps and the studies are often of low quality. We also found that DevOps is supported by a culture of collaboration, automation, measurement, information sharing and web service usage. DevOps benefits IS development and operations performance. It also has positive effects on web service development and quality assurance performance. Finally, our mapping study suggests that more research is needed to quantify these effects.},
author = {Erich, Floris and Amrit, Chintan and Daneva, Maya},
doi = {10.13140/2.1.5125.1201},
isbn = {978-3-319-13834-3},
issn = {978-3-319-13834-3},
journal = {ESEM '14: Proceedings of the 8th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
number = {October},
pages = {27},
title = {{DevOps Literature Review}},
year = {2014}
}
@book{Pathania2017,
abstract = {Follow this step-by-step guide for creating a continuous delivery pipeline using all of the new features in Jenkins 2.0 such as Pipeline as a Code, multi-branch pipeline, and more. You will learn three crucial elements for achieving a faster software delivery pipeline: a fungible build/test environment, manageable and reproducible pipelines, and a scalable build/test infrastructure. Pro Continuous Delivery demonstrates how to create a highly available, active/passive Jenkins server using some niche technologies.},
author = {Pathania, Nikhil},
doi = {10.1007/978-1-4842-2913-2},
isbn = {978-1-4842-2912-5},
pages = {288},
title = {{Pro Continuous Delivery}},
url = {http://link.springer.com/10.1007/978-1-4842-2913-2},
year = {2017}
}
@article{UrRahman2016,
abstract = {In organizations that use DevOps practices, software changes can be deployed as fast as 500 times or more per day. Without adequate involvement of the security team, rapidly deployed software changes are more likely to contain vulnerabilities due to lack of adequate reviews. The goal of this paper is to aid software practitioners in integrating security and DevOps by summarizing experiences in utilizing security practices in a DevOps environment. We analyzed a selected set of Internet artifacts and surveyed representatives of nine organizations that are using DevOps to systematically explore experiences in utilizing security practices. We observe that the majority of the software practitioners have expressed the potential of common DevOps activities, such as automated monitoring, to improve the security of a system. Furthermore, organizations that integrate DevOps and security utilize additional security activities, such as security requirements analysis and performing security configurations. Additionally, these teams also have established collaboration between the security team and the development and operations teams.},
author = {{Ur Rahman}, Akond Ashfaque and Williams, Laurie},
doi = {10.1145/2896941.2896946},
isbn = {9781450341578},
journal = {Proceedings of the International Workshop on Continuous Software Evolution and Delivery - CSED '16},
keywords = {devops,security,software practices,survey},
pages = {70--76},
title = {{Software security in DevOps}},
url = {http://dl.acm.org/citation.cfm?doid=2896941.2896946},
year = {2016}
}
@article{Rodriguez2017,
abstract = {The software intensive industry is moving towards the adoption of a value-driven and adaptive real-time business paradigm. The traditional view of software as an item that evolves through releases every few months is being replaced by the continuous evolution of software functionality. This study aims to classify and analyse the literature related to continuous deployment in the software domain in order to scope the phenomenon, provide an overview of the state-of-the-art, investigate the scientific evidence in the reported results and identify areas suitable for further research. We conducted a systematic mapping study and classified the continuous deployment literature. The benefits and challenges related to continuous deployment were also analysed. RESULTS: The systematic mapping study includes 50 primary studies published between 2001 and 2014. An in-depth analysis of the primary studies revealed ten recurrent themes that characterize continuous deployment and provide researchers with directions for future work. In addition, a set of benefits and challenges of which practitioners may take advantage were identified. CONCLUSION: Overall, although the topic area is very promising, it is still in its infancy, thus offering a plethora of new opportunities for both researchers and software intensive companies.},
author = {Rodr{\'{i}}guez, Pilar and Haghighatkhah, Alireza and Lwakatare, Lucy Ellen and Teppola, Susanna and Suomalainen, Tanja and Eskeli, Juho and Karvonen, Teemu and Kuvaja, Pasi and Verner, June M. and Oivo, Markku},
doi = {10.1016/j.jss.2015.12.015},
isbn = {0164-1212},
issn = {01641212},
journal = {Journal of Systems and Software},
keywords = {Continuous deployment,Software development,Systematic mapping study},
pages = {263--291},
title = {{Continuous deployment of software intensive products and services: A systematic mapping study}},
volume = {123},
year = {2017}
}
@article{Shahin2017,
abstract = {—Context: Continuous practices, i.e., continuous integration, delivery, and deployment, are the software development industry practices that enable organizations to frequently and reliably release new features and products. With the increasing interest in and literature on continuous practices, it is important to systematically review and synthesize the approaches, tools, challenges, and practices reported for adopting and implementing continuous practices. Objective: This research aimed at systematically reviewing the state of the art of continuous practices to classify approaches and tools, identify challenges and practices in this regard, and identify the gaps for future research. Method: We used systematic literature review (SLR) method for reviewing the peer-reviewed papers on continuous practices published between 2004 and 1st June 2016. We applied thematic analysis method for analysing the data extracted from reviewing 69 papers selected using predefined criteria. Results: We have identified thirty approaches and associated tools, which facilitate the implementation of continuous practices in the following ways: (1) ―reducing build and test time in continuous integration (CI)‖; (2) ―increasing visibility and awareness on build and test results in CI‖; (3) ―supporting (semi-) automated continuous testing‖; (4) ―detecting violations, flaws and faults in CI‖; (5) ―addressing security and scalability issues in deployment pipeline‖, and (6) ―improving dependability and reliability of deployment process‖. We have also determined a list of critical factors such as ―testing (effort and time)‖, ―team awareness and transparency‖, ―good design principles‖, ―customer‖, ―highly skilled and motivated team‖, ―application domain‖, and ―appropriate infrastructure‖ that should be carefully considered when introducing continuous practices in a given organization. The majority of the reviewed papers were validation (34.7{\%}) and evaluation (36.2{\%}) research types. This review also reveals that continuous practices have been successfully applied to both greenfield and maintenance projects.},
archivePrefix = {arXiv},
arxivId = {1703.07019},
author = {Shahin, Mojtaba and {Ali Babar}, Muhammad and Zhu, Liming},
doi = {10.1109/ACCESS.2017.2685629},
eprint = {1703.07019},
isbn = {2169-3536 VO - 5},
issn = {21693536},
journal = {IEEE Access},
keywords = {Continuous integration,continuous delivery,continuous deployment,continuous software engineering,empirical software engineering,systematic literature review},
pages = {3909--3943},
title = {{Continuous Integration, Delivery and Deployment: A Systematic Review on Approaches, Tools, Challenges and Practices}},
volume = {5},
year = {2017}
}
@techreport{Puppet2017,
abstract = {The 2014 State of DevOps Report by Puppet Labs, IT Revolution Press and ThoughtWorks is an analysis of more than 9,200 survey responses from technical professionals around the world, making this the largest and most comprehensive DevOps study to date.},
author = {Puppet and {DevOps Research and Assessment}},
file = {:C$\backslash$:/Users/david/Dropbox/UNAL/2018-1/Tesis/DevOps - State of the Art/Refrences/DevOps/2017-state-of-devops-report-puppet-dora.pdf:pdf},
institution = {Puppet},
mendeley-groups = {Documentos/Tesis/DevOps,Documentos/Tesis/Bibliografia},
pages = {31},
title = {{State of DevOps Report 2017}},
url = {https://puppet.com/resources/whitepaper/state-of-devops-report/thank-you},
year = {2017}
}

@article{LopezAguilar2015,
abstract = {En este documento de investigaci{\'{o}}n se presenta una soluci{\'{o}}n que involucra software de c{\'{o}}digo abierto que permite utilizar las mejores pr{\'{a}}cticas del desarrollo de software aplicadas al mantenimiento, configuraci{\'{o}}n y administraci{\'{o}}n de la infraestructura. Dicha soluci{\'{o}}n es aplicada en Adblock Plus, la extensi{\'{o}}n m{\'{a}}s descargada de internet con m{\'{a}}s de 350 millones de descargas y 60 millones de usuarios activos al mes, siendo un producto usado por millones de personas es necesario contar con una infraestructura que permita escalar r{\'{a}}pidamente as{\'{i}} como modificarla de acuerdo a los constantes cambios que se presentan.},
author = {{L{\'{o}}pez Aguilar}, Francisco Josu{\'{e}}},
pages = {1--72},
title = {{Aprovisionamiento autom{\'{a}}tico de infraestructura y de configuraci{\'{o}}n de la infraestructura. El caso Adblock Plus}},
year = {2015}
}
@phdthesis{Marco2016,
author = {Marco, Jim{\'{e}}nez and Guillermo},
keywords = {incidencias de software,ingenier{\'{i}}a de telecomunicaciones,ti,un caso pr{\'{a}}ctico en},
pages = {102},
school = {Universitat Polit{\'{e}}cnica de Catalunya},
title = {{DevOps, la nueva tendencia en el desarrollo de sistemas TI, un caso pr{\'{a}}ctico en el an{\'{a}}lisis de incidencias de software}},
url = {https://upcommons.upc.edu/bitstream/handle/2117/85074/An{\'{a}}lisis de incidentes en el {\'{a}}mbito TIC con DevOps.pdf?sequence=1{\&}isAllowed=y http://upcommons.upc.edu/handle/2117/85074},
year = {2016}
}
